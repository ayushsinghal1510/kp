{
    "variables": {
        "user_input": {
            "type": "str"
        },
        "llm_response": {
            "type": "str"
        },
        "feedback": {
            "type": "str"
        },
        "score": {
            "type": "float"
        },
        "diagnosis_conversation_history": {
            "type": "list",
            "default": []
        },
        "speak": {
            "type": "str"
        },
        "node_type": {
            "type": "str"
        },
        "reasoning_conversation_history": {
            "type": "list",
            "default": []
        },
        "feedback_questions": {
            "type": "str",
            "value": "1. Did the student ask about onset? 2. Did the student check for red flags? 3. Did the student ask about social history?"
        },
        "end_diagnosis": {
            "type": "str"
        },
        "movement": {
            "type": "list",
            "default": []
        }
    },
    "start_node": "greeting1",
    "nodes": {
        "greeting1": {
            "type": "out",
            "parameters": {
                "out_dict": {
                    "speak": "Hello! Lets start the session"
                }
            },
            "next": "input1"
        },
        "input1": {
            "type": "input",
            "parameters": {
                "input_variables": {
                    "user_input": "str"
                }
            },
            "next": ["llm" , "transcription1"]
        },
        "transcription1" : {
            "type": "out",
            "parameters": {
                "variables": [
                    "user_input"
                ]
            }
        },
        "llm": {
            "type": "llm",
            "parameters": {
                "input_variables": {
                    "user_input": {
                        "type": "str",
                        "description": "The input text from the user."
                    }
                },
                "prompt_template": "base_llm",
                "system_prompt": "Physiotherapy Case: Right Shoulder Pain and Neck Pain with Numbness\\n\\nPatient Profile: Name: Janice Wong... (Rest of your prompt)... return small cased 'yes' or 'no' depending on the situation.\n\n***\n\n# SYSTEM KERNEL: OUTPUT SERIALIZATION PROTOCOL\n\n**CRITICAL DIRECTIVE: SILENT EXECUTION**\nYou are a headless data processing engine. You have NO console, NO stdout, and NO chat interface.\nYou must not output your thinking process, steps, analysis, or 'Here is the answer'.\n**Outputting anything other than the raw JSON string is a system failure.**\n\n**Payload vs. Container:**\n1.  **The Payload (Content):** This is the content requested by the user (e.g., Markdown tables, paragraphs). Generate this internally based on the User Prompt and Persona.\n2.  **The Container (Format):** You must package that Payload into the specific JSON format defined below.\n\n**Strict Constraints:**\n1.  **JSON ONLY:** Start immediately with `{`. End immediately with `}`.\n2.  **No Markdown Fences:** Do NOT wrap the JSON in ```json ... ```.\n3.  **No Thinking Logs:** Do NOT output 'Step 1...', 'Analyzing...', or 'The final answer is...'.\n4.  **Escaping:** If the content contains newlines (like a Markdown table), you must escape them (`\\n`).\n\n---\n\n### TARGET JSON TEMPLATE\n(This defines the keys you must populate. Do not copy the 'type' or 'description' fields into your output; use them only to understand what to generate.)\n\n```json\n{json.dumps(return_type, indent=4)}\n```\n\n**Generate the raw JSON string now:**",
                "service": "groq",
                "model": "llama-3.3-70b-versatile",
                "history_key": "diagnosis_conversation_history",
                "llm_return_type": {
                    "speak": {
                        "type": "str",
                        "description": "The response generated by the LLM based on the user input."
                    },
                    "movement": {
                        "type": "list",
                        "description": "For now keep it empty only"
                    },
                    "end_diagnosis": {
                        "type": "str",
                        "description": "Indicates whether the diagnosis session should end."
                    }
                }
            },
            "next": [
                "response1",
                "judge_if_diagnosis_is_ended"
            ]
        },
        "response1": {
            "type": "out",
            "parameters": {
                "variables": [
                    "speak",
                    "end_diagnosis",
                    "movement"
                ]
            }
        },
        "judge_if_diagnosis_is_ended": {
            "type": "conditional",
            "parameters": {
                "input_variables": {
                    "end_diagnosis": {}
                },
                "mappings": {
                    "yes": "feedback",
                    "no": "input1"
                }
            }
        },
        "feedback": {
            "type": "llm",
            "parameters": {
                "input_variables": {
                    "diagnosis_conversation_history": {
                        "type": "list",
                        "description": "the conversation hsitory of the diagnosis"
                    },
                    "feedback_questions": {
                        "type": "str",
                        "description": "The feedback questions"
                    }
                },
                "prompt_template": "base_llm",
                "system_prompt": "You are an AI assistant designed to evaluate a medical student's performance... (Rest of your prompt)...\n\n***\n\n# SYSTEM KERNEL: OUTPUT SERIALIZATION PROTOCOL\n\n**CRITICAL DIRECTIVE: SILENT EXECUTION**\nYou are a headless data processing engine. You have NO console, NO stdout, and NO chat interface.\nYou must not output your thinking process, steps, analysis, or 'Here is the answer'.\n**Outputting anything other than the raw JSON string is a system failure.**\n\n**Payload vs. Container:**\n1.  **The Payload (Content):** This is the content requested by the user (e.g., Markdown tables, paragraphs). Generate this internally based on the User Prompt and Persona.\n2.  **The Container (Format):** You must package that Payload into the specific JSON format defined below.\n\n**Strict Constraints:**\n1.  **JSON ONLY:** Start immediately with `{`. End immediately with `}`.\n2.  **No Markdown Fences:** Do NOT wrap the JSON in ```json ... ```.\n3.  **No Thinking Logs:** Do NOT output 'Step 1...', 'Analyzing...', or 'The final answer is...'.\n4.  **Escaping:** If the content contains newlines (like a Markdown table), you must escape them (`\\n`).\n\n---\n\n### TARGET JSON TEMPLATE\n(This defines the keys you must populate. Do not copy the 'type' or 'description' fields into your output; use them only to understand what to generate.)\n\n```json\n{json.dumps(return_type, indent=4)}\n```\n\n**Generate the raw JSON string now:**",
                "service": "groq",
                "model": "llama-3.3-70b-versatile",
                "history_key": "feedback_conversation_history",
                "llm_return_type": {
                    "speak": {
                        "type": "str",
                        "description": "The feedback text"
                    },
                    "score": {
                        "type": "str",
                        "description": "The feedback score after evaluation"
                    }
                }
            },
            "next": [
                "feedbacko",
                "greeting2"
            ]
        },
        "feedbacko": {
            "type": "out",
            "parameters": {
                "variables": [
                    "speak",
                    "score"
                ]
            }
        },
        "greeting2": {
            "type": "out",
            "parameters": {
                "out_dict": {
                    "speak": "Hello! Lets start the reasoning session"
                }
            },
            "next": "input2"
        },
        "input2": {
            "type": "input",
            "parameters": {
                "input_variables": {
                    "user_input": "str"
                }
            },
            "next": ["reasoning" , "transcription2"]
        },
        "transcription2" : {
            "type": "out",
            "parameters": {
                "variables": [
                    "user_input"
                ]
            }
        },
        "reasoning": {
            "type": "llm",
            "parameters": {
                "input_variables": {
                    "conversation_history": {
                        "type": "list",
                        "description": "the conversation hsitory of the diagnosis"
                    },
                    "feedback_questions": {
                        "type": "str",
                        "description": "The feedback questions"
                    }
                },
                "prompt_template": "base_llm",
                "system_prompt": "You are an AI assistant designed to evaluate a medical student's performance... (Rest of your prompt)...\n\n***\n\n# SYSTEM KERNEL: OUTPUT SERIALIZATION PROTOCOL\n\n**CRITICAL DIRECTIVE: SILENT EXECUTION**\nYou are a headless data processing engine. You have NO console, NO stdout, and NO chat interface.\nYou must not output your thinking process, steps, analysis, or 'Here is the answer'.\n**Outputting anything other than the raw JSON string is a system failure.**\n\n**Payload vs. Container:**\n1.  **The Payload (Content):** This is the content requested by the user (e.g., Markdown tables, paragraphs). Generate this internally based on the User Prompt and Persona.\n2.  **The Container (Format):** You must package that Payload into the specific JSON format defined below.\n\n**Strict Constraints:**\n1.  **JSON ONLY:** Start immediately with `{`. End immediately with `}`.\n2.  **No Markdown Fences:** Do NOT wrap the JSON in ```json ... ```.\n3.  **No Thinking Logs:** Do NOT output 'Step 1...', 'Analyzing...', or 'The final answer is...'.\n4.  **Escaping:** If the content contains newlines (like a Markdown table), you must escape them (`\\n`).\n\n---\n\n### TARGET JSON TEMPLATE\n(This defines the keys you must populate. Do not copy the 'type' or 'description' fields into your output; use them only to understand what to generate.)\n\n```json\n{json.dumps(return_type, indent=4)}\n```\n\n**Generate the raw JSON string now:**",
                "service": "groq",
                "model": "llama-3.3-70b-versatile",
                "history_key": "reasoning_conversation_history",
                "llm_return_type": {
                    "speak": {
                        "type": "str",
                        "description": "The feedback score"
                    },
                    "score": {
                        "type": "str",
                        "description": "The feedback score after evaluation"
                    }
                }
            },
            "next": [
                "response2",
                "input2"
            ]
        },
        "response2": {
            "type": "out",
            "parameters": {
                "variables": [
                    "speak"
                ]
            }
        }
    }
}
